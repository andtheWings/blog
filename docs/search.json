[
  {
    "objectID": "posts/beta_dist/index.html",
    "href": "posts/beta_dist/index.html",
    "title": "Estimating Risk for Rare Events in Small Areas where the Denominator is Unknown",
    "section": "",
    "text": "This blog post is an adaptation of methods taught by David Robinson in his book Introduction to Empirical Bayes: Examples from Baseball Statistics.\nMy research group has compiled a dataset that counts the number of cases of Sudden Unexpected Infant Death (SUID) in each census tract of Cook County, IL from 2015-2019. We want an accurate way to estimate the risk of SUID in each tract using this data. SUID is defined as any case of death in a baby less than age 1 year old that does not have a known cause before a medical autopsy is performed. While the state of Illinois releases statistics about SUID for the county as a whole, we think it’s important to understand this phenomenon at a more granular geographic level. That way, we have a better understanding of geographic disparities and service agencies can more precisely target their interventions.\nThe goal of this post is to convince you that Bayesian techniques offer a more principled way to estimate a risk process when the amount of observed data has limitations by itself."
  },
  {
    "objectID": "posts/beta_dist/index.html#intro-to-the-data",
    "href": "posts/beta_dist/index.html#intro-to-the-data",
    "title": "Estimating Risk for Rare Events in Small Areas where the Denominator is Unknown",
    "section": "Intro to the Data",
    "text": "Intro to the Data\nHere’s what our dataset looks like:\n\nlibrary(tidyverse)\nlibrary(leaflet)\n\nsuid_base_table <- \n    read_csv(here::here(\"data\", \"suid_snapshot_2022_08_31.csv\")) |>\n    # Remove rows with NA values for count of SUID cases or for population under five\n    filter(!is.na(suid_count) & !is.na(pop_under_five)) |> \n    select(fips, suid_count, pop_under_five)\n\nsuid_base_table\n\n# A tibble: 1,284 × 3\n          fips suid_count pop_under_five\n         <dbl>      <dbl>          <dbl>\n 1 17031010100          0            364\n 2 17031010201          0            592\n 3 17031010202          0            257\n 4 17031010300          0            312\n 5 17031010400          0             38\n 6 17031010501          0            277\n 7 17031010502          0            139\n 8 17031010503          0             65\n 9 17031010600          1            177\n10 17031010701          0            288\n# … with 1,274 more rows\n\n\nEach row is an individual census tract. The fips column lists each tract’s unique identifier, suid_count is the number of SUID cases that took place from 2015-2019, and pop_under_five is the population of children under age five as estimated by the U.S. Census’ American Community Survey.\nIt’s important to note that SUID is a rare event. The vast majority of census tracts did not suffer any cases of SUID during this time period. Here’s a histogram to illustrate:\n\n\n\n\n\nThe first challenge in estimating the risk is we don’t have the proper denominator. SUID incidence is typically reported as cases per 100,000 live births. However, we don’t have disaggregated counts of live births in each census tract. The best approximation I have found is pop_under_five, which I hope reasonably mirrors the number of live births over a five-year period. Here are approximated incidences for each tract using pop_under_five as denominator:\n\nsuid_incidence_table <-\n    suid_base_table |> \n    mutate(suid_incidence = round(suid_count / pop_under_five * 1E5, 2))\n\nsuid_incidence_table\n\n# A tibble: 1,284 × 4\n          fips suid_count pop_under_five suid_incidence\n         <dbl>      <dbl>          <dbl>          <dbl>\n 1 17031010100          0            364             0 \n 2 17031010201          0            592             0 \n 3 17031010202          0            257             0 \n 4 17031010300          0            312             0 \n 5 17031010400          0             38             0 \n 6 17031010501          0            277             0 \n 7 17031010502          0            139             0 \n 8 17031010503          0             65             0 \n 9 17031010600          1            177           565.\n10 17031010701          0            288             0 \n# … with 1,274 more rows\n\n\nLet’s calculate the mean of these values:\n\nmean(suid_incidence_table$suid_incidence)\n\n[1] NaN\n\n\nHmm, it’s seems like there are some “Not a number” values messing up the calculation. Let’s filter them out:\n\nmean(suid_incidence_table$suid_incidence, na.rm = TRUE)\n\n[1] Inf\n\n\nThat’s also not what we were looking for. What’s going on?\nA problem that emerges from using pop_under_five as the denominator is that five tracts are estimated to have zero children under the age of five. In such cases, R calculates the incidence as NaN (not a number) when suid_count is zero and as Inf (infinity) when suid_count is anything greater than zero:\n\nsuid_incidence_table |> \n    filter(pop_under_five == 0)\n\n# A tibble: 5 × 4\n         fips suid_count pop_under_five suid_incidence\n        <dbl>      <dbl>          <dbl>          <dbl>\n1 17031081000          0              0            NaN\n2 17031280800          0              0            NaN\n3 17031380200          0              0            NaN\n4 17031670100          1              0            Inf\n5 17031834900          1              0            Inf\n\n\nWe know that the true risk for these tracts can’t be a non-existent number or infinitely large, so we’ll do our best adjust for these circumstances:\n\nsuid_incidence_table <-\n    suid_incidence_table |> \n    mutate(\n        suid_incidence = \n            case_when(\n                # If incidence is NaN, change to 0\n                is.nan(suid_incidence) ~ 0,\n                # If it's Inf, change to 100,000\n                is.infinite(suid_incidence) ~ 1E5,\n                # Otherwise, keep as is\n                TRUE ~ suid_incidence\n            )\n    )\n\nNow let’s try and calculate the mean:\n\nmean(suid_incidence_table$suid_incidence)\n\n[1] 339.1101\n\n\nA much more sensible number, although it still seems like an overestimate compared to the overall incidence for Cook County, which is 88.3 cases per 100,000 births per Illinois Department of Health.\nLet’s take a look at the census tracts with lowest and highest incidences:\n\nsuid_incidence_table |> \n    arrange(suid_incidence) |> \n    head(10)\n\n# A tibble: 10 × 4\n          fips suid_count pop_under_five suid_incidence\n         <dbl>      <dbl>          <dbl>          <dbl>\n 1 17031010100          0            364              0\n 2 17031010201          0            592              0\n 3 17031010202          0            257              0\n 4 17031010300          0            312              0\n 5 17031010400          0             38              0\n 6 17031010501          0            277              0\n 7 17031010502          0            139              0\n 8 17031010503          0             65              0\n 9 17031010701          0            288              0\n10 17031010702          0            530              0\n\n\n\nsuid_incidence_table |> \n    arrange(desc(suid_incidence)) |> \n    head(10)\n\n# A tibble: 10 × 4\n          fips suid_count pop_under_five suid_incidence\n         <dbl>      <dbl>          <dbl>          <dbl>\n 1 17031670100          1              0        100000 \n 2 17031834900          1              0        100000 \n 3 17031530502          2             15         13333.\n 4 17031081401          3             30         10000 \n 5 17031831300          1             10         10000 \n 6 17031480300          1             13          7692.\n 7 17031834700          5             92          5435.\n 8 17031612000          2             37          5405.\n 9 17031670200          4             74          5405.\n10 17031690300          2             46          4348.\n\n\nOn both extremes, the incidence values seem intuitively implausible when used to characterize the underlying risk for SUID. On one end, we shouldn’t expect that a tract’s risk for SUID was zero just because there were no observed cases. SUID is rare, so it’s expected that many tracts will count zero cases just by luck of the draw.\nOn the other end, notice how the tracts with highest incidence of SUID also tend to have low populations under five. Let’s take an aside for a minute and think about flipping a coin and using the results to estimate whether that coin is weighted to favor a certain side. If you flip a coin three times and get heads every single time, do you think it’s actually weighted to favor heads? What about if you flip it 500 times and still get heads every single time? You should be a lot more confident after 500 coin flips that the coin is truly weighted because you’ve accumulated more evidence. Similarly, think of every live birth as a coin flip that accumulates evidence about the underlying risk of SUID. The more live births there are, the more confident we can be that the observed incidence matches the true risk for SUID. Said another way, census tracts with high incidence but low counts of pop_under_five might just be very unlucky, rather than truly at higher risk.\nGiven these limitations of approximating incidence, we are going to use a Bayesian approach to adjust estimations to incorporate our “prior” expectations of what the underlying risk process should look like."
  },
  {
    "objectID": "posts/beta_dist/index.html#step-1-set-your-prior-expectations",
    "href": "posts/beta_dist/index.html#step-1-set-your-prior-expectations",
    "title": "Estimating Risk for Rare Events in Small Areas where the Denominator is Unknown",
    "section": "Step 1: Set your prior expectations",
    "text": "Step 1: Set your prior expectations\nWe are going to use the “Beta distribution” to represent our prior expectations. The Beta distribution is not nearly as well known as others like the normal distribution (aka Bell Curve), but the Beta is particularly well suited to represent a plausible values for a risk process. Check out David Robinson’s post here for more explanation. The Beta distribution has two “parameters”. The number of observed events is represented by \\(\\alpha\\) (SUID cases) and the number of trials that don’t result in an event is represented by \\(\\beta\\) (live births that don’t result in SUID, aka survivals). Let’s try using Cook County’s overall incidence of SUID and count of live births to set our prior expectations:\n\n# Sourced from Illinois Vital Statistics\n# https://dph.illinois.gov/topics-services/life-stages-populations/infant-mortality/sids/sleep-related-death-statistics.html\noverall_incidence <- 88.3 / 1E5 # per live birth for Cook County in 2014\noverall_incidence\n\n[1] 0.000883\n\n\n\n# https://dph.illinois.gov/data-statistics/vital-statistics/birth-statistics.html\ntotal_live_births <- 139398 # for Cook County from 2015-2019\nextrapolated_cases <- overall_incidence * total_live_births\nextrapolated_cases\n\n[1] 123.0884\n\n\n\nextrapolated_survivals <- total_live_births - extrapolated_cases\nextrapolated_survivals\n\n[1] 139274.9\n\n\nA cool thing about the Beta distribution is it will adjust it’s shape to reflect the number of observations (aka evidence) we give it. I’ll try and illustrate by rescaling the parameters to reflect the relative number of live births (coin flips of evidence) in the county versus in a typical census tract.\n\nscaling_factor <- median(suid_incidence_table$pop_under_five) / total_live_births\nscaling_factor\n\n[1] 0.001531586\n\n\nLet’s simulate two Beta distributions of 1,284 census tracts. One will use parameters reflecting the amount of evidence accumulated for a whole county’s worth of live births, versus just a census tract’s worth of live births.\n\n\n\n\n\nBoth distributions have the same ratio of cases (\\(\\alpha\\)) to survivals (\\(\\beta\\)), so their mean expected SUID Risk is about the same at 88.3 cases per 100,000 live births, but the blue distribution observed a county’s worth of live birth evidence (139,398), so its range of expected values is much more compact (about 70 to 120) than a census tract’s worth of live birth evidence (estimating risk anywhere from 0 to 500).\nIn Bayesian analysis, we combine our prior expectations with observed data to get a “posterior” estimate. In this case, I want the prior expectation to weigh about the same as the observed data, so I’ll use census-tract-scaled parameters in my prior."
  },
  {
    "objectID": "posts/beta_dist/index.html#step-2-combine-the-prior-expectation-and-observed-data",
    "href": "posts/beta_dist/index.html#step-2-combine-the-prior-expectation-and-observed-data",
    "title": "Estimating Risk for Rare Events in Small Areas where the Denominator is Unknown",
    "section": "Step 2: Combine the prior expectation and observed data",
    "text": "Step 2: Combine the prior expectation and observed data\nTo get each posterior estimate of risk from the Beta distribution, we are going to perform the following calculation:\n\\[ \\frac{cases_{prior} + cases_{observed}}{cases_{prior} + cases_{observed} + survivals_{prior} + survivals_{observed}} = \\frac{0.189 + cases_{observed}}{0.189 + cases_{observed} + 213.311 + survivals_{observed}} \\]\n\nprior_alpha <- extrapolated_cases * scaling_factor\nprior_beta <- extrapolated_survivals * scaling_factor\nsuid_posterior_table <-\n    suid_incidence_table |> \n    mutate(\n        posterior_alpha = prior_alpha + suid_count,\n        posterior_beta = prior_beta + pop_under_five - suid_count\n    ) |> \n    mutate(\n        posterior_risk = posterior_alpha / (posterior_alpha + posterior_beta) * 1E5,\n        # Use the Beta Distribution Quantile function to also get 95% credible intervals\n        posterior_risk_low = qbeta(0.025, posterior_alpha, posterior_beta) * 1E5,\n        posterior_risk_high = qbeta(0.975, posterior_alpha, posterior_beta) * 1E5,\n        .before = posterior_alpha\n    )\n\nsuid_posterior_table\n\n# A tibble: 1,284 × 9\n          fips suid_co…¹ pop_u…² suid_…³ poste…⁴ poste…⁵ poste…⁶ poste…⁷ poste…⁸\n         <dbl>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 17031010100         0     364      0     32.6 3.56e-7    253.   0.189    577.\n 2 17031010201         0     592      0     23.4 2.55e-7    181.   0.189    805.\n 3 17031010202         0     257      0     40.1 4.38e-7    310.   0.189    470.\n 4 17031010300         0     312      0     35.9 3.92e-7    278.   0.189    525.\n 5 17031010400         0      38      0     75.0 8.20e-7    580.   0.189    251.\n 6 17031010501         0     277      0     38.4 4.20e-7    298.   0.189    490.\n 7 17031010502         0     139      0     53.5 5.84e-7    414.   0.189    352.\n 8 17031010503         0      65      0     67.7 7.40e-7    524.   0.189    278.\n 9 17031010600         1     177    565.   304.  1.27e+1   1041.   1.19     389.\n10 17031010701         0     288      0     37.6 4.11e-7    291.   0.189    501.\n# … with 1,274 more rows, and abbreviated variable names ¹​suid_count,\n#   ²​pop_under_five, ³​suid_incidence, ⁴​posterior_risk, ⁵​posterior_risk_low,\n#   ⁶​posterior_risk_high, ⁷​posterior_alpha, ⁸​posterior_beta\n\n\nLet’s visualize how our posterior estimates of risk relate to incidence calculations and prior expectations:\n\n\n\n\n\nOn the Y axis, we have 9 census tracts for which we’ve estimated risk. We label each tract with the observed data used to calculate approximate incidence. For example, the top row shows a census tract that observed zero cases of SUID and had a population under five of 1,011 children. Each approximate incidence is marked on the x axis as a hollow circle for reference. Each filled black circle marks our posterior estimate of SUID risk and is flanked by a 95% credible interval (the Bayesian cousin to the confidence interval). The dashed vertical line marks our prior expectation of risk as observed for the whole county.\nWhat I want you to notice is how the posterior estimate represents a tug-of-war between the prior expectation (dashed line) and the observed data (hollow circle). The prior expectation is able to pull our estimates away from extreme observed incidence values (like 0 in the top three rows, or over 5000 in the bottom three rows) to more plausible values. This balance between the forces of expectation and observation is what makes Bayesian estimation so powerful!"
  },
  {
    "objectID": "posts/beta_dist/index.html#geographic-pattern",
    "href": "posts/beta_dist/index.html#geographic-pattern",
    "title": "Estimating Risk for Rare Events in Small Areas where the Denominator is Unknown",
    "section": "Geographic Pattern?",
    "text": "Geographic Pattern?\nWhen we map census tracts with the 100 highest and 100 lowest estimates of SUID risk, we notice a pattern starting to emerge. The lowest estimates are concentrating on the West/South sides of Chicago and the Southern suburbs. These areas are where historic trends of segregation have caused concentration of socioeconomic vulnerability. When you think about it, we might expect these areas to have higher risk of SUID even before we observe the data. In a future blog post, I’ll show how we can use auxiliary information about tracts (like location or SES) to fine tune our prior expectations of risk for a better posterior estimate."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Daniel P. Hall Riggins Blog",
    "section": "",
    "text": "suid\n\n\ninfant-safety\n\n\npediatrics\n\n\nepidemiology\n\n\nstatistics\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2022\n\n\nDaniel P. Hall Riggins, MD\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsuid\n\n\ninfant-safety\n\n\npediatrics\n\n\n\n\n\n\n\n\n\n\n\nAug 31, 2022\n\n\nDaniel P. Hall Riggins, MD\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Daniel P. Hall Riggins Blog",
    "section": "",
    "text": "Statement of Purpose\nThe laws of most jurisdictions throughout the world automatically confer exclusive Copyright and Related Rights (defined below) upon the creator and subsequent owner(s) (each and all, an “owner”) of an original work of authorship and/or a database (each, a “Work”).\nCertain owners wish to permanently relinquish those rights to a Work for the purpose of contributing to a commons of creative, cultural and scientific works (“Commons”) that the public can reliably and without fear of later claims of infringement build upon, modify, incorporate in other works, reuse and redistribute as freely as possible in any form whatsoever and for any purposes, including without limitation commercial purposes. These owners may contribute to the Commons to promote the ideal of a free culture and the further production of creative, cultural and scientific works, or to gain reputation or greater distribution for their Work in part through the use and efforts of others.\nFor these and/or other purposes and motivations, and without any expectation of additional consideration or compensation, the person associating CC0 with a Work (the “Affirmer”), to the extent that he or she is an owner of Copyright and Related Rights in the Work, voluntarily elects to apply CC0 to the Work and publicly distribute the Work under its terms, with knowledge of his or her Copyright and Related Rights in the Work and the meaning and intended legal effect of CC0 on those rights.\n\nCopyright and Related Rights. A Work made available under CC0 may be protected by copyright and related or neighboring rights (“Copyright and Related Rights”). Copyright and Related Rights include, but are not limited to, the following:\n\n\nthe right to reproduce, adapt, distribute, perform, display, communicate, and translate a Work;\nmoral rights retained by the original author(s) and/or performer(s);\npublicity and privacy rights pertaining to a person’s image or likeness depicted in a Work;\nrights protecting against unfair competition in regards to a Work, subject to the limitations in paragraph 4(a), below;\nrights protecting the extraction, dissemination, use and reuse of data in a Work;\ndatabase rights (such as those arising under Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, and under any national implementation thereof, including any amended or successor version of such directive); and\nother similar, equivalent or corresponding rights throughout the world based on applicable law or treaty, and any national implementations thereof.\n\n\nWaiver. To the greatest extent permitted by, but not in contravention of, applicable law, Affirmer hereby overtly, fully, permanently, irrevocably and unconditionally waives, abandons, and surrenders all of Affirmer’s Copyright and Related Rights and associated claims and causes of action, whether now known or unknown (including existing as well as future claims and causes of action), in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “Waiver”). Affirmer makes the Waiver for the benefit of each member of the public at large and to the detriment of Affirmer’s heirs and successors, fully intending that such Waiver shall not be subject to revocation, rescission, cancellation, termination, or any other legal or equitable action to disrupt the quiet enjoyment of the Work by the public as contemplated by Affirmer’s express Statement of Purpose.\nPublic License Fallback. Should any part of the Waiver for any reason be judged legally invalid or ineffective under applicable law, then the Waiver shall be preserved to the maximum extent permitted taking into account Affirmer’s express Statement of Purpose. In addition, to the extent the Waiver is so judged Affirmer hereby grants to each affected person a royalty-free, non transferable, non sublicensable, non exclusive, irrevocable and unconditional license to exercise Affirmer’s Copyright and Related Rights in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “License”). The License shall be deemed effective as of the date CC0 was applied by Affirmer to the Work. Should any part of the License for any reason be judged legally invalid or ineffective under applicable law, such partial invalidity or ineffectiveness shall not invalidate the remainder of the License, and in such case Affirmer hereby affirms that he or she will not (i) exercise any of his or her remaining Copyright and Related Rights in the Work or (ii) assert any associated claims and causes of action with respect to the Work, in either case contrary to Affirmer’s express Statement of Purpose.\nLimitations and Disclaimers.\n\n\nNo trademark or patent rights held by Affirmer are waived, abandoned, surrendered, licensed or otherwise affected by this document.\nAffirmer offers the Work as-is and makes no representations or warranties of any kind concerning the Work, express, implied, statutory or otherwise, including without limitation warranties of title, merchantability, fitness for a particular purpose, non infringement, or the absence of latent or other defects, accuracy, or the present or absence of errors, whether or not discoverable, all to the greatest extent permissible under applicable law.\nAffirmer disclaims responsibility for clearing rights of other persons that may apply to the Work or any use thereof, including without limitation any person’s Copyright and Related Rights in the Work. Further, Affirmer disclaims responsibility for obtaining any necessary consents, permissions or other rights required for any use of the Work.\nAffirmer understands and acknowledges that Creative Commons is not a party to this document and has no duty or obligation with respect to this CC0 or use of the Work.\n\nFor more information, please see http://creativecommons.org/publicdomain/zero/1.0/"
  },
  {
    "objectID": "posts/benefits_of_bayesian_beta/index.html",
    "href": "posts/benefits_of_bayesian_beta/index.html",
    "title": "What Makes Bayesian Methods Different and Why Should I Care?",
    "section": "",
    "text": "In my last post, I showed how to estimate risk of sudden unexpected infant death (SUID) in census tracts using Bayesian methods. The Bayesian approach is a separate branch of statistics from the Frequentist approach that most of us learned in school. Historically, Frequentist methods were so dominantly favored, many people may not have been aware that the statistics they were learning were termed “Frequentist” and that there was an alternative “Bayesian” approach available.\nMy objective for this post is to outline enough of the Bayesian approach to explain why it is better suited to the use-case of estimating SUID risk in small areas, then to give a set of examples to build intuition around how the method is working under the hood."
  },
  {
    "objectID": "posts/benefits_of_bayesian_beta/index.html#the-challenge",
    "href": "posts/benefits_of_bayesian_beta/index.html#the-challenge",
    "title": "What Makes Bayesian Methods Different and Why Should I Care?",
    "section": "The Challenge",
    "text": "The Challenge\nEpidemiology works with seemingly idiosyncratic denominators when representing incidence or risk. For example, the overall incidence of SUID in Cook County, IL for 2014 was 88.3 cases per 100,000 live-births. While it would be just as mathematically valid to represent it as 0.000883 cases per single live-birth, that doesn’t make sense in human terms. When considering a rare event, you want to use a large pool of people as your reference denominator.\nLet’s assume the incidence of 88.3 accurately represents the underlying risk of SUID in the county for 2014. If we know that there were 140,000 live births in the next five years, then we would expect there to be about 124 cases of SUID.\n\\[Expected \\space New \\space Cases \\space in \\space the \\space County = Incidence \\times Live \\space Births =\\]\n\\[\\frac{88.3 \\space cases}{100,000 \\space live \\space births} \\times 140,000 \\space live \\space births \\approx 124 \\space cases \\]\nBut let’s zoom in to a single census tract where there were 240 live births over the same time period. Using the formula above, we would expect to observe zero cases. However, given what we know about incidence for the whole county, we wouldn’t observe zero cases and assume the underlying risk for that individual tract was actually zero. Estimating risk is hard when an event is rare and/or the reference pool of people is small."
  },
  {
    "objectID": "posts/benefits_of_bayesian_beta/index.html#why-use-bayesian-methods-to-solve-this-challenge",
    "href": "posts/benefits_of_bayesian_beta/index.html#why-use-bayesian-methods-to-solve-this-challenge",
    "title": "What Makes Bayesian Methods Different and Why Should I Care?",
    "section": "Why Use Bayesian Methods to Solve this Challenge?",
    "text": "Why Use Bayesian Methods to Solve this Challenge?\nThe “Frequentist” approach to statistics uses data in isolation from “prior knowledge”. If we observe 0 cases out of 240 live births in a census tract, our estimate of the underlying risk is 0 cases per 100,000 live births–even if our knowledge about the county as a whole suggests the underlying risk is closer to 88.3. Furthermore, if we want to make inferences about our data, Frequentist methods require a certain threshold sample size (for example n = 30) to be accurate. If the pool of live-births in a census tract is something small like 13 total, than we expect up front that our estimate is going to be out of whack.\nIn contrast, Bayesian methods weigh the observed data against prior knowledge. If we have a lot of observed data, the final estimate will rely mostly on that data and look similar to the Frequentist estimate. But if we don’t observe a lot of data, the prior knowledge weighs more heavily into the estimate and will diverge away from the Frequentist estimate."
  },
  {
    "objectID": "posts/benefits_of_bayesian_beta/index.html#examples",
    "href": "posts/benefits_of_bayesian_beta/index.html#examples",
    "title": "What Makes Bayesian Methods Different and Why Should I Care?",
    "section": "Examples",
    "text": "Examples\nAnother important distinguishing characteristic of Bayesian methods, is that they represent the uncertainty of an estimate using a distribution. In my previous post, we used a “Beta distribution” and outlined our process for specifying its parameters to represent our prior knowledge as follows:\n\n\nCode\nlibrary(tidyverse)\n\nshape1 <- 0.189\nshape2 <- 213\n\nggplot(tibble(x = c(0, 1)), aes(x)) +\n    stat_function(\n        fun = dbeta,\n        args = list(\n            shape1 = shape1,\n            shape2 = shape2\n        ),\n        color = \"red\"\n    ) +\n    stat_function(\n        fun = dbeta,\n        args = list(\n            shape1 = shape1,\n            shape2 = shape2\n        ),\n        geom = \"area\",\n        fill = \"pink\",\n        alpha = 0.5,\n    ) +\n    labs(\n        \n        x = \"SUID Risk (cases per 100,000 live-births)\",\n        y = \"Density\"\n    ) +\n    scale_y_sqrt() +\n    scale_x_sqrt(labels = scales::label_comma(scale = 1E5)) +\n    coord_cartesian(xlim = c(0, 0.1)) +\n    theme_light()\n\n\n\n\n\nThe shaded red area represents the full range of plausible SUID risk values represented by our prior knowledge. The mean of this curve is 88.3, but we’re using the whole distribution to say the true risk could vary anywhere from 0 to 2500. Next, we can overlay a range of plausible values based on hypothetical data where we observed 1 case of SUID in 270 live births:\n\n\nCode\ny <- 1\nn <- 270\n\nlike_scaled <- function(x) {\n    like_fun <- function(x) {\n        dbinom(x = y, size = n, prob = x)\n    }\n    scale_c <- integrate(like_fun, lower = 0, upper = 1)[[1]]\n    like_fun(x)/scale_c\n}\n\nggplot(tibble(x = c(0, 1)), aes(x)) +\n    stat_function(\n        fun = dbeta,\n        args = list(\n            shape1 = shape1,\n            shape2 = shape2\n        ),\n        color = \"red\"\n    ) +\n    stat_function(\n        fun = dbeta,\n        args = list(\n            shape1 = shape1,\n            shape2 = shape2\n        ),\n        geom = \"area\",\n        fill = \"pink\",\n        alpha = 0.5,\n    ) +\n    stat_function(\n        fun = like_scaled, \n        color = \"blue\"\n    ) +\n    stat_function(\n        fun = like_scaled,\n        geom = \"area\",\n        fill = \"lightblue\",\n        alpha = 0.5\n    ) +\n    labs(\n        title = paste0(\"Cases = \", as.character(y), \", Live Births = \", as.character(n)),\n        x = \"SUID Risk (cases per 100,000 live-births)\",\n        y = \"Density\"\n    ) +\n    scale_y_sqrt() +\n    scale_x_sqrt(labels = scales::label_comma(scale = 1E5)) +\n    coord_cartesian(xlim = c(0, 0.1)) +\n    theme_light()\n\n\n\n\n\nThe data alone thinks the most plausible risk values are much higher than our prior understanding suggested. Bayesian methods help us weigh between these two somewhat conflicting sources of information by combining the prior expectations and the observed data to give us a “posterior” estimate:\n\n\nCode\nplot_beta_binom_variation <- function(shape1_num, shape2_num, y_num, n_num) {\n    \n    like_scaled <- function(x) {\n        like_fun <- function(x) {\n            dbinom(x = y_num, size = n_num, prob = x)\n         }\n        scale_c <- integrate(like_fun, lower = 0, upper = 1)[[1]]\n        like_fun(x)/scale_c\n    }\n\n    prior_fun <- function(x) {\n        dbeta(x, shape1 = shape1_num, shape2 = shape2_num)\n    }\n\n    posterior_fun <- function(x) {\n        dbeta(x, shape1 = shape1_num + y_num, shape2 = shape2_num + n_num - y_num)\n    }\n    \n    ggplot(tibble(x = c(0, 1)), aes(x)) +\n    stat_function(fun = prior_fun, aes(color = \"Prior\"), alpha = 0.75) +\n    stat_function(fun = like_scaled, aes(color = \"Data\"), alpha = 0.75) +\n    stat_function(fun = posterior_fun, aes(color = \"Posterior\"), alpha = 0.75) +\n    geom_vline(\n        xintercept = (shape1_num + y_num) / (shape1_num + shape2_num + n_num - y_num),\n        linetype = \"dashed\"\n    ) +\n    labs(\n        title = paste0(\"Cases = \", as.character(y_num), \", Live Births = \", as.character(n_num), \",\\n Average Posterior Estimate = \", as.character(round((shape1_num + y_num) / (shape1_num + shape2_num + n_num - y_num) * 1E5)), \" cases per 100,000 live births\"),\n        x = \"SUID Risk (cases per 100,000 live-births)\",\n        y = \"Density\"\n    ) +\n    scale_y_sqrt() +\n    scale_x_sqrt(labels = scales::label_comma(scale = 1E5)) +\n    coord_cartesian(xlim = c(0, 0.1)) +\n    scale_color_manual(\n        \"\",\n        values = c(\n            Prior = \"red\",\n            `Data` = \"blue\",\n            Posterior = \"purple\"\n        ),\n        breaks = c(\n            \"Prior\",\n            \"Data\",\n            \"Posterior\"\n        )\n    ) +\n    theme_light()\n}\n\nplot_beta_binom_variation(0.189, 213, 1, 270)\n\n\n\n\n\nI’ve taken out the shaded regions for visual clarity, but the area under each curve is still representing the most plausible values. Look how the purple “posterior” curve distributes itself in between the red and blue ones. Bayesian statistics weighed our prior expectations against the data and estimated the true risk to be somewhere in between.\nTo get some better intuition about what’s happening, let’s look at some extreme scenarios. First, what if we observe zero cases in a census tract with very few live births?\n\n\nCode\nplot_beta_binom_variation(0.189, 213, 0, 10)\n\n\n\n\n\nIn this example, the data gave us very little information so the prior expectation and posterior estimation curves look almost identical. The blue curve is very spread out, indicating a wide range of plausible risk values based on the data alone.\n\n\nCode\nplot_beta_binom_variation(0.189, 213, 0, 1000)\n\n\n\n\n\nThis example considers a census tract where we still observed zero cases, but there were many live births, meaning there were more opportunities for a case of SUID to happen. Given there were so many observed live births, the data weighs much more heavily into the posterior, which estimates the true risk (16) to be lower than our prior expectations (88.3).\n\n\nCode\nplot_beta_binom_variation(0.189, 213, 5, 1000)\n\n\n\n\n\nIn this example, we still observed 1000 live births, so the data heavily weighed into our posterior, but we increased the case count to 5, so the estimated true risk increased to a whopping 429.\n\n\nCode\nplot_beta_binom_variation(0.189, 213, 5, 50)\n\n\n\n\n\nAnd finally, in this example, we still observed 5 cases, but we decreased the number of live births to 50. Using the data alone, we calculated the risk to be very high, but the posterior curve hung back toward the prior curve because the weight of our observed data was less than when we observed 1000 live births."
  },
  {
    "objectID": "posts/benefits_of_bayesian_beta/index.html#wrap-up",
    "href": "posts/benefits_of_bayesian_beta/index.html#wrap-up",
    "title": "What Makes Bayesian Methods Different and Why Should I Care?",
    "section": "Wrap-Up",
    "text": "Wrap-Up\nSome people argue that Bayesian statistics introduce too much subjectivity by letting us incorporate “arbitrary” prior expectations. Bayesians counter that statistical analysis always involved subjective interpretation. When we look at risk estimates based on the data alone, we adjust our trust in those numbers based on external knowledge. Bayesian methods simply give us a way to more formally define and weigh those expectations into our estimates. In the case of SUID estimation for small populations in small geographic areas, it’s really helpful to moderate extreme estimates created by limited data using the Bayesian prior."
  }
]