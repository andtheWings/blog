{
  "hash": "d9fc37deb9539dbe135be0ee4cf4f01c",
  "result": {
    "markdown": "---\ntitle: \"Modeling Live Births from Population Counts: A First-Time MCMC Model\"\nauthor: \"Daniel P. Hall Riggins, MD\"\ndate: \"2022-09-19\"\ncategories: [suid, infant-safety, pediatrics, epidemiology, statistics]\ncode-fold: true\n---\n\n\n## Intro\n\nIn my [previous post](https://danielriggins.com/blog/posts/beta_dist/), I estimated risk of sudden unexpected infant death in census tracts while acknowledging that I was using **the wrong denominator**. I should have been using the count of live births in each census tract, but I have not been able to find counts of live births at such a fine geographic scale. The data we do have available from the U.S. Census is the count of children under five years old (5yo) per census tract, so I was using that as a proxy for the count of live births over a five year period. In the future, I want to be more accurately approximate the true denominator.\n\nMy objective for this blog post is to fit models of counts of live births regressed from counts of children under 5yo at the *county* level so I can estimate counts of live births at the *census tract* level. \n\nSidenote: Despite my enthusiasm for Bayesian statistics, I have little practice with fitting models using [MCMC](https://towardsdatascience.com/monte-carlo-markov-chain-mcmc-explained-94e3a6c8de11) methods, so this is also a chance for me to explore doing so with the R package {[brms](https://paul-buerkner.github.io/brms/index.html)}. [Section 6.2](https://www.bayesrulesbook.com/chapter-6.html#markov-chains-via-rstan) of \"Bayes Rules\" describes MCMC methods more in detail if interested, but if not, just note that when Bayesian models get sufficiently complex, you use MCMC sampling to approximate a model solution when it would otherwise be too mathematically difficult. \n\n![Don't worry, I'm not sure I do either.](mcmc_baby.jpg)\n\n## Data Exploration\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(tidyverse)\nlibrary(ggdist)\nlibrary(brms)\nlibrary(insight)\nlibrary(performance)\n\ntheme_set(theme_light())\n\nmodel_data <- read_csv(here::here(\"data\", \"births_and_under_five_by_county_2022_09_17.csv\"))\ntract_data <- read_csv(here::here(\"data\", \"under_five_by_tract_2022_09_19.csv\"))\n```\n:::\n\n\nLet's start with some exploration of the variables and their relationships in the model data: Here's a glimpse at what we're working with:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(model_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 3,142\nColumns: 3\n$ GEOID          <chr> \"01099\", \"01079\", \"01077\", \"01097\", \"01009\", \"01067\", \"…\n$ pop_under_five <dbl> 20733, 32924, 92729, 413210, 57826, 17205, 164542, 2970…\n$ births         <dbl> 1052, 1804, 4652, 27790, 3318, 837, 9488, 1513, 6555, 1…\n```\n:::\n:::\n\n\n### Univariate\n\nHere is the distribution of our county-level target parameter, counts of live births:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_data |> \n    ggplot(aes(x = births)) +\n    stat_dotsinterval() +\n    labs(\n        title = \"Counts of Live Births in Each County of the USA from 2015-2019\",\n        x = \"Count of Live Births\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis distribution is highly skewed right, so it's hard to intuit visually. As a couple of supplements, here's a table of percentiles:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(model_data$births)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    0%    25%    50%    75%   100% \n     0    612   1481   3931 623037 \n```\n:::\n:::\n\n\nAnd here is the same distribution on a log-transformed x-axis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_data |> \n    ggplot(aes(x = births + 1E-10)) +\n    stat_dotsinterval() +\n    labs(\n        title = \"Counts of Live Births in Each County of the USA from 2015-2019\",\n        x = \"Count of Live Births on Log Scale\",\n        y = \"Density\"\n    ) +\n    scale_x_log10()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nNotice the one county with an outlier of purportedly zero births.\n\nPerhaps unsurprisingly, we observe similar trends from our predictor variable, the count of children under 5yo (pop_under_five):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(model_data, aes(x = pop_under_five)) +\n    stat_dotsinterval() +\n    labs(\n        title = \"Counts of Children Under 5yo in Each County of the USA from 2015-2019\",\n        x = \"Count of Children Under 5yo\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(model_data$pop_under_five)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         0%         25%         50%         75%        100% \n      86.00    10902.50    25726.00    68072.75 10039107.00 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(model_data, aes(x = pop_under_five)) +\n    stat_dotsinterval() +\n    labs(\n        title = \"Counts of Children Under 5yo in Each County of the USA from 2015-2019\",\n        x = \"Count of Children Under 5yo on Log Scale\",\n        y = \"Density\"\n    ) +\n    scale_x_log10()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n### Bivariate\n\nLet's test whether our target variable and predictor have a linear relationship:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_data |> \n    correlation::cor_test(x = \"pop_under_five\", y = \"births\") |> \n    plot() +\n    labs(\n        x = \"Count of Children Under 5yo\",\n        y = \"Count of Live Births\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nAwesome, the correlation coefficient is extremely high and the p value is below 0.01, let's make a linear model! Not so fast, as noted earlier, it's hard to assess these relationships visually, because they are so skewed. Indeed, if you log transform either axis, you start to see how the relationship breaks down:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_data |> \n    correlation::cor_test(x = \"pop_under_five\", y = \"births\") |> \n    plot() +\n    labs(\n        x = \"Count of Children Under 5yo on a Log Scale\",\n        y = \"Count of Live Births\"\n    ) +\n    scale_x_log10()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nIt looks like a linear line describes the relationship well in the middle range, but not so much at small or large values of the predictor variable. To get a better understanding, let's go ahead and fit a linear model and check its assumptions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreq_linear_model <- lm(births ~ pop_under_five, data = model_data)\n\ncheck_model(\n    freq_linear_model, \n    check = c(\"qq\", \"homogeneity\"),\n    panel = FALSE \n) |> plot()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$HOMOGENEITY\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n$QQ\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n:::\n\n\nI won't claim to be an expert at reading model diagnostics, but these plots pretty demonstrably suggest that the model is violating assumptions of homogeneity of variance as well as normality. As suggested by our previous scatterplot, this translates to the model poorly predicting birth counts at extreme values of the predictor variable. That's not to say a linear model isn't useful. I think especially if you were to subset it to data within a certain order of magnitude, it would perform decently well. But let's see if we can do better than that!\n\n## Bayesian Modeling Using MCMC\n\nAs mentioned in the intro, I'm using this post as an opportunity to practice regression modeling under a Bayesian MCMC framework rather than the traditional Frequentist approach. Refer back to my [last post](https://danielriggins.com/blog/posts/benefits_of_bayesian_beta/) on what makes Bayesian methods unique and when you might choose to use them. Long story short, they allow you to incorporate your prior knowledge into a model and they perform better when data is limited by small sample sizes or rare events. In this particular use case (predicting counts of live births from counts of children under 5yo), we have a large robust data set to draw upon, so I don't expect Bayesian methods to perform that differently from Frequentist ones, but I figure that will make it easier to practice without the modeling process being too finicky.\n\nPackages like {[brms](https://paul-buerkner.github.io/brms/index.html)} and {[rstanarm](http://mc-stan.org/rstanarm/index.html)} make it easy to take a pre-existing Frequentist model and drop it into a Bayesian framework. For example you can take our previous linear model:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nfreq_linear_model <- lm(births ~ pop_under_five, data = model_data)\n```\n:::\n\n\nAnd wrap it in the function brm() instead:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-13_79732e69510bd059208465445dc2b0bf'}\n\n```{.r .cell-code  code-fold=\"false\"}\nbayesian_linear_model <- brm(births ~ pop_under_five, data = model_data)\n```\n:::\n\n\nIf you're following along at home, try not to be alarmed by long output produced by the code above. Basically, the software back-end is just sending you regular updates as it approximates the model solution.\n\nTo find a better fit for the data than that from linear regression, let's try modeling the outcome as a negative binomial distribution. I expect this to be more accurate because it is designed to describe discrete, count variables and it is flexible enough to fit the data even when it is very right skewed. For an improved fit, I will also log transform the predictor variable to make it more closely approximate a normal distribution:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-14_bdfc2257efb04bebfdc8b5360dd0fb92'}\n\n```{.r .cell-code  code-fold=\"false\"}\nnegbinomial_model <- brm(\n    births ~ log(pop_under_five), \n    data = model_data, \n    family = negbinomial()\n)\n```\n:::\n\n\nLet's compute some metrics comparing relative performance between the two models:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-15_2a432acbd2562636ab86b22bc6318f72'}\n\n```{.r .cell-code}\ncompare_performance(bayesian_linear_model, negbinomial_model, rank = TRUE) |> print_html()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"volipcvkpz\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#volipcvkpz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#volipcvkpz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#volipcvkpz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#volipcvkpz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#volipcvkpz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#volipcvkpz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#volipcvkpz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#volipcvkpz .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#volipcvkpz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#volipcvkpz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#volipcvkpz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#volipcvkpz .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#volipcvkpz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#volipcvkpz .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#volipcvkpz .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#volipcvkpz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#volipcvkpz .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#volipcvkpz .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#volipcvkpz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#volipcvkpz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#volipcvkpz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#volipcvkpz .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#volipcvkpz .gt_left {\n  text-align: left;\n}\n\n#volipcvkpz .gt_center {\n  text-align: center;\n}\n\n#volipcvkpz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#volipcvkpz .gt_font_normal {\n  font-weight: normal;\n}\n\n#volipcvkpz .gt_font_bold {\n  font-weight: bold;\n}\n\n#volipcvkpz .gt_font_italic {\n  font-style: italic;\n}\n\n#volipcvkpz .gt_super {\n  font-size: 65%;\n}\n\n#volipcvkpz .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#volipcvkpz .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#volipcvkpz .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#volipcvkpz .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#volipcvkpz .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#volipcvkpz .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#volipcvkpz .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  <thead class=\"gt_header\">\n    <tr>\n      <td colspan=\"7\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Comparison of Model Performance Indices</td>\n    </tr>\n    \n  </thead>\n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Name</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Model</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\">R2</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\">RMSE</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\">WAIC weights</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\">LOOIC weights</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Performance-Score</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td class=\"gt_row gt_left\">bayesian_linear_model</td>\n<td class=\"gt_row gt_center\">brmsfit</td>\n<td class=\"gt_row gt_center\">0.99</td>\n<td class=\"gt_row gt_center\">2479.34</td>\n<td class=\"gt_row gt_center\">0.00e+00</td>\n<td class=\"gt_row gt_center\">0.007</td>\n<td class=\"gt_row gt_center\">50.00%</td></tr>\n    <tr><td class=\"gt_row gt_left\">negbinomial_model</td>\n<td class=\"gt_row gt_center\">brmsfit</td>\n<td class=\"gt_row gt_center\">0.98</td>\n<td class=\"gt_row gt_center\">2650.21</td>\n<td class=\"gt_row gt_center\">1.00</td>\n<td class=\"gt_row gt_center\">0.993</td>\n<td class=\"gt_row gt_center\">50.00%</td></tr>\n  </tbody>\n  <tfoot class=\"gt_sourcenotes\">\n    <tr>\n      <td class=\"gt_sourcenote\" colspan=\"7\">NA</td>\n    </tr>\n  </tfoot>\n  \n</table>\n</div>\n```\n:::\n:::\n\n\nThe compare_performance() function's ranking algortihm is a little confused because the linear model does better with the data at hand; it accounts for variance in the outcome slightly better (higher R2 metric) and has slightly smaller residuals from its predictions (smaller RMSE metric). However, its important to note that both R2 and RMSE are in similar orders of magnitude for both models. More importantly for us, the WAIC and LOOIC metrics strongly favor the negative binomial model. LOOIC and WAIC try to balance between accurately fitting the data at hand while **maintaining generalizability to new data**. Before we generalize though, let's visualize what the negative binomial model's fit looks like with the data at hand:\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-16_1dfd3fd85f8d40e2c88a4e1a2ced22ed'}\n\n```{.r .cell-code}\npp_check(negbinomial_model) +\n    scale_x_log10() + \n    scale_color_manual(\n        values = c(\"red\", \"blue\"),\n        labels = c(\"Observed\", \"Predicted\")\n    ) +\n    labs(\n        title = \"Predictions Vs. Observations for Negative Binomial Model \\n Predicting Counts of Live Births from Counts of Children Under 5yo\",\n        x = \"Live Birth Count\",\n        y = \"Density\"\n    ) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nThe predicted blue distributions closely trace the observed red distribution, visually supporting the strong fit suggested by our metrics.\n\n## New Predictions\n\nThe differences in generalizability between the two models will become more apparent when we turn to the original goal and predict counts of live births at the **census tract level**. Remember that the U.S. Census provides estimates of the counts of children under 5yo in census tracts, but does not provide estimates of counts of live births. Here is the distribution of our predictor variable at the new geographic level:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntract_data |> \n    ggplot(aes(x = pop_under_five)) +\n    stat_dotsinterval() +\n    labs(\n        title = \"Counts of Children Under 5yo in \\n Each Census Tract of Cook County Illinois from 2015-2019\",\n        x = \"Count of Children under 5yo\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nNotice that the counts of children under 5yo at the tract level are distributed at much lower values than those at the county level (makes sense). This should make us cautious since we'll be extrapolating our models to a new range of data. Let's start with what the linear model predicts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntract_data$lm_predicted_births <- get_predicted(bayesian_linear_model, newdata = tract_data)\n\ntract_data |> \n    ggplot(aes(x = lm_predicted_births)) +\n    stat_dotsinterval() +\n    labs(\n        title = \"Counts of Live Births Predicted Using Linear Regression \\n in Each Census Tract of Cook County, Illinois from 2015-2019\",\n        x = \"Linear Predicted Count of Live Births\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n Uh oh, every single count is predicted by the linear model to be negative. You can't have a negative count!\n\nLet's see how the negative binomial model does:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntract_data$nbinom_predicted_births <- get_predicted(negbinomial_model, newdata = tract_data)\n\ntract_data |> \n    ggplot(aes(x = nbinom_predicted_births)) +\n    stat_dotsinterval() +\n    labs(\n        title = \"Counts of Live Births Predicted Using Negative Binomial Regression \\n in Each Census Tract of Cook County, Illinois from 2015-2019\",\n        x = \"Negative Binomial Predicted Count of Live Births\",\n        y = \"Density\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nThat makes much more sense, the predicted counts go no lower than zero, and these predictions correspond to tracts where the counts of children under 5yo were also zero:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(\n    head(arrange(tract_data, pop_under_five), 3),\n    slice_sample(tract_data, n = 3),\n    slice_max(tract_data, order_by = pop_under_five, n = 3)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 4\n        GEOID pop_under_five lm_predicted_births nbinom_predicted_births\n        <dbl>          <dbl> <gt_prdct>          <gt_prdct>             \n1 17031980100              0 -344.9329            0.000000              \n2 17031980000              0 -344.9329            0.000000              \n3 17031670100              0 -344.9329            0.000000              \n4 17031821402             88 -339.3627            4.739437              \n5 17031808301            157 -334.9951            8.508460              \n6 17031230900            266 -328.0956           14.497711              \n7 17031803606            969 -283.5968           53.554069              \n8 17031020702            923 -286.5085           50.985029              \n9 17031842100            917 -286.8883           50.650037              \n```\n:::\n:::\n\n\nThe negative binomial model generalizes better and creates more sensible predictions in a new range of predictor values. In future work, I'll use these estimated counts of live births to estimate the underlying risk process for sudden unexpected infant death. Thanks for reading!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}